"""
ë°ì´í„° ì ì¬ ìŠ¤í¬ë¦½íŠ¸
PDF/CSV â†’ í…ìŠ¤íŠ¸ ë¶„í•  â†’ ì„ë² ë”© â†’ ChromaDB ì ì¬ (ë¡œì»¬ PersistentClient)
- í˜¸í™˜ ìŠ¤íƒ: chromadb==0.4.15, langchain-chroma==0.1.x, Python 3.11 (Windows OK)
"""

import os
import sys
import shutil
import random
from pathlib import Path
from typing import List

import numpy as np
import pandas as pd
from tqdm import tqdm
import torch
from transformers import set_seed

# ---- LangChain / Chroma (ê¶Œì¥ ìµœì‹  ìŠ¤íƒ) ----
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
import chromadb  # PersistentClient
from langchain.schema import Document
# --------------------------------------------

# ---- í”„ë¡œì íŠ¸ ë‚´ë¶€ ëª¨ë“ˆ ----
sys.path.insert(0, str(Path(__file__).parent.parent))
from rag_system.config import Config
from rag_system.data_parser import parse_pdf_files, get_file_paths
from rag_system.text_splitter import split_documents, add_title_to_document
from rag_system.csv_loader import load_documents_from_csv, validate_csv_format


# ===========================
# ìœ í‹¸: ì‹œë“œ ë° ë””ë ‰í„°ë¦¬ ë³´ì¥
# ===========================
def set_all_seeds(seed: int):
    """torch/numpy/random ì¬í˜„ì„± ë³´ì¥"""
    torch.manual_seed(seed)
    set_seed(seed)
    np.random.seed(seed)
    random.seed(seed)


def ensure_dirs():
    """Config ìƒì˜ ì£¼ìš” ë””ë ‰í„°ë¦¬ ìƒì„±"""
    dirs = [
        getattr(Config, "DATA_DIR", None),
        getattr(Config, "PARSED_DIR", None),
        getattr(Config, "VECTORDB_DIR", None),
        getattr(Config, "OUTPUT_DIR", None),
    ]
    for p in dirs:
        if p:
            Path(p).mkdir(parents=True, exist_ok=True)


# ===========================
# Chroma ì´ˆê¸°í™” (ìŠ¤í‚¤ë§ˆ ì¶©ëŒ ìë™ë³µêµ¬)
# ===========================
def init_chroma_client(db_path: str, collection_name: str) -> chromadb.Client:
    """chromadb PersistentClient ìƒì„± + ì»¬ë ‰ì…˜ ì¡´ì¬ ë³´ì¥"""
    def _new_client():
        return chromadb.PersistentClient(path=db_path)

    client = _new_client()

    try:
        try:
            client.get_collection(collection_name)
        except Exception:
            client.create_collection(collection_name)
        return client
    except Exception as e:
        msg = str(e).lower()
        if "no such column" in msg or "schema" in msg or "topic" in msg:
            print("[ê²½ê³ ] ChromaDB ìŠ¤í‚¤ë§ˆ ì¶©ëŒ ê°ì§€ â†’ ë²¡í„°DB í´ë” ì¬ìƒì„±")
            shutil.rmtree(db_path, ignore_errors=True)
            client = _new_client()
            client.create_collection(collection_name)
            return client
        raise


# ===========================
# ë©”ì¸ ì‹¤í–‰
# ===========================
def main():
    # 0) ì‹œë“œ ê³ ì •
    seed = getattr(Config, "RANDOM_SEED", 42)
    set_all_seeds(seed)

    # 1) í´ë” ë³´ì¥ + ìë™ ìƒì„±
    ensure_dirs()

    data_dir = Path(Config.DATA_DIR)
    if not data_dir.exists():
        print(f"[ìë™ ìƒì„±] ë°ì´í„° í´ë” ìƒì„±: {data_dir}")
        data_dir.mkdir(parents=True, exist_ok=True)

    # ìƒ˜í”Œ CSV ìë™ ìƒì„± (PDF/CSV ëª¨ë‘ ì—†ì„ ê²½ìš°)
    has_pdf = any(data_dir.glob("*.pdf"))
    has_csv = any(data_dir.glob("*.csv"))
    if not (has_pdf or has_csv):
        sample_csv = data_dir / "sample.csv"
        sample_csv.write_text(
            "title,text,prep_text,source\n"
            "ì˜ˆì‹œ ì œëª©,ì˜ˆì‹œ ë‚´ìš©,ì˜ˆì‹œ ë‚´ìš©,ìƒ˜í”Œ íŒŒì¼\n",
            encoding="utf-8"
        )
        print(f"[ì°¸ê³ ] PDF/CSV ì—†ìŒ â†’ ìƒ˜í”Œ CSV ìƒì„±: {sample_csv}")

    # 2) PDF íŒŒì‹±
    print("=" * 50)
    print("1ë‹¨ê³„: PDF íŒŒì¼ íŒŒì‹±")
    print("=" * 50)
    pdf_files = list(data_dir.glob("*.pdf"))
    if pdf_files:
        try:
            parsed_files = parse_pdf_files(
                pdf_folder_path=str(data_dir),
                output_dir=str(Config.PARSED_DIR),
                max_len=getattr(Config, "PDF_MAX_LEN", 500000),
                max_lvl=getattr(Config, "PDF_MAX_LVL", 4),
            )
            print(f"PDF íŒŒì‹± ì™„ë£Œ: {len(parsed_files)}ê°œ íŒŒì¼")
        except Exception as e:
            print(f"[ê²½ê³ ] PDF íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e} (CSVë§Œ ì‚¬ìš©)")
            parsed_files = []
    else:
        print("PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. CSVë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        parsed_files = []

    # 3) CSV ë¡œë“œ
    print("\n" + "=" * 50)
    print("2ë‹¨ê³„: ë¬¸ì„œ ë¡œë“œ (CSV í¬í•¨)")
    print("=" * 50)
    file_paths: List[str] = []
    if Config.PARSED_DIR.exists():
        file_paths.extend(get_file_paths(str(Config.PARSED_DIR)))
    file_paths.extend([str(f) for f in data_dir.glob("*.csv")])

    if not file_paths and not parsed_files:
        print("[ì˜¤ë¥˜] ë¡œë“œí•  CSV ë˜ëŠ” PDF ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    all_documents: List[Document] = []
    for file_path in tqdm(file_paths, desc="ë¬¸ì„œ ë¡œë”©"):
        if file_path.lower().endswith(".csv"):
            validation = validate_csv_format(file_path)
            if not validation.get("valid", False):
                print(f"[ê²½ê³ ] {file_path} - {validation.get('message', 'í˜•ì‹ ì˜¤ë¥˜')}")
                continue
            try:
                docs = load_documents_from_csv(file_path)
                all_documents.extend(docs)
                print(f"  âœ“ {file_path}: {len(docs)}ê°œ ë¬¸ì„œ ë¡œë“œ")
            except Exception as e:
                print(f"  âœ— {file_path} ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue

    if not all_documents:
        print("[ì˜¤ë¥˜] ë¬¸ì„œë¥¼ í•˜ë‚˜ë„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    # 4) í…ìŠ¤íŠ¸ ë¶„í• 
    print("\n" + "=" * 50)
    print("3ë‹¨ê³„: í…ìŠ¤íŠ¸ ë¶„í• ")
    print("=" * 50)
    split_docs = split_documents(
        all_documents,
        chunk_size=getattr(Config, "CHUNK_SIZE", 800),
        chunk_overlap=getattr(Config, "CHUNK_OVERLAP", 100),
    )
    split_docs = [add_title_to_document(doc) for doc in split_docs]
    print(f"ì´ {len(split_docs)}ê°œì˜ ì²­í¬ ìƒì„± ì™„ë£Œ")

    # 5) ì„ë² ë”© + Chroma ì ì¬
    print("\n" + "=" * 50)
    print("4ë‹¨ê³„: ChromaDB ë²¡í„° ìŠ¤í† ì–´ ì ì¬")
    print("=" * 50)

    try:
        model_name = getattr(Config, "EMBEDDING_MODEL_NAME", "intfloat/multilingual-e5-small")
        device = getattr(Config, "DEVICE", "cpu")

        print(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name}")
        embeddings = HuggingFaceEmbeddings(
            model_name=model_name,
            model_kwargs={"device": device},
        )
        print(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ. (ì‚¬ìš© ì¥ì¹˜: {device})")

        db_path = str(Config.VECTORDB_DIR)
        Path(db_path).mkdir(parents=True, exist_ok=True)
        collection_name = Config.COLLECTION_NAME

        print(f"ChromaDB ë¡œì»¬ í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì €ì¥ ìœ„ì¹˜: {db_path})")
        client = init_chroma_client(db_path, collection_name)

        # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±
        try:
            client.delete_collection(collection_name)
            print(f"ê¸°ì¡´ ì»¬ë ‰ì…˜ '{collection_name}' ì‚­ì œ ì™„ë£Œ (ë®ì–´ì“°ê¸°)")
        except Exception:
            print(f"ê¸°ì¡´ ì»¬ë ‰ì…˜ '{collection_name}' ì—†ìŒ â†’ ìƒˆë¡œ ìƒì„± ì˜ˆì •")

        client.create_collection(collection_name)
        print(f"ì»¬ë ‰ì…˜ '{collection_name}' ìƒˆë¡œ ìƒì„± ì™„ë£Œ")

        # Chroma ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        vector_store = Chroma(
            client=client,
            collection_name=collection_name,
            embedding_function=embeddings,
            persist_directory=db_path,
        )

        print(f"{len(split_docs)}ê°œì˜ ì²­í¬ë¥¼ ChromaDBì— ì¶”ê°€ ì¤‘...")
        vector_store.add_documents(split_docs)

        count = vector_store._collection.count()
        print(f"\nâœ… ë²¡í„° ìŠ¤í† ì–´ ì ì¬ ì™„ë£Œ! (ì´ {count}ê°œ ì²­í¬ ì €ì¥)")
        print(f"ì €ì¥ ìœ„ì¹˜: {db_path}")
        print(f"ì»¬ë ‰ì…˜ ì´ë¦„: {collection_name}")

    except ImportError as ie:
        print("[ì˜¤ë¥˜] í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. requirementsë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        print(f"ìƒì„¸: {ie}")
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ë²¡í„° ìŠ¤í† ì–´ ì ì¬ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    main()

# ë²„ì „ ì„¤ëª…
# ğŸ“ í´ë” ìë™ ìƒì„±	data, output, parsed, vectordb ìë™ ìƒì„±
# ğŸ§¾ ìƒ˜í”Œ CSV ìë™ ìƒì„±	PDF/CSV ì—†ì„ ê²½ìš° data/sample.csv ìë™ ìƒì„±
# ğŸ’¾ persist() ì œê±°	langchain_chroma í˜¸í™˜ ì™„ë£Œ (ì—ëŸ¬ ì œê±°ë¨)
# âš¡ ìŠ¤í‚¤ë§ˆ ìë™ ë³µêµ¬	â€œno such columnâ€¦â€ ì˜¤ë¥˜ ì‹œ í´ë” ìë™ ë¦¬ì…‹
# ğŸŒ ê¸°ë³¸ ì„ë² ë”©	intfloat/multilingual-e5-small (ë¹ ë¥´ê³  ê°€ë²¼ì›€)
# ğŸ§  ì™„ì „ ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥	ì²« ì‹¤í–‰ ì‹œ ë°”ë¡œ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± í…ŒìŠ¤íŠ¸ ê°€ëŠ¥

#ì‹¤í–‰ìˆœì„œ
# cd C:\rag_chatbot
# .\.venv\Scripts\activate
# python rag_system\ingest.py